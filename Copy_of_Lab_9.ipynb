{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidSchineis/Math-Physics/blob/main/Copy_of_Lab_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Abstract\n",
        "This lab explores matrix transformations and basic image compression using Python. We began by applying transformations such as rotation, scaling, and sheering to varying shapes and images, visualizing how these transformations happen and how the order of operations effects the result. Then, we used np.diag to diagonalize matrices, verifying the relationship between a matrix, eigenvalues, and eigenvectors. Then, we brought these concepts to image compression by projecting an image onto a set of eigenvectors from the k largest eigenvalues. This lab demonstrates how linear algebra principles are at the core of image transformations, diagonalization, and compression in Python."
      ],
      "metadata": {
        "id": "oCKkTuSKzOPu"
      },
      "id": "oCKkTuSKzOPu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d101b199",
      "metadata": {
        "id": "d101b199"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import pi, cos, sin, tan, cosh, sinh, tanh\n",
        "from PIL import Image\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "url='https://upload.wikimedia.org/wikipedia/commons/thumb/8/83/Solar_system.jpg/193px-Solar_system.jpg'\n",
        "headers ={\n",
        "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36'\n",
        "}\n",
        "x=requests.get(url, stream=True,headers=headers)\n",
        "\n",
        "# Load the image\n",
        "image = Image.open(x.raw)\n",
        "\n",
        "# Convert the image to a NumPy array\n",
        "image_array = np.array(image)\n",
        "\n",
        "display(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cad22e3f",
      "metadata": {
        "id": "cad22e3f"
      },
      "source": [
        "We can transform this image in a variety of different ways. Rotation can be achieved through multiplying the transformation matrix of\n",
        "$$ \\begin{bmatrix}\n",
        "\\cos(\\theta) & -\\sin(\\theta)\\\\\n",
        "\\sin(\\theta) & \\cos(\\theta)\n",
        "\\end{bmatrix} $$\n",
        "and your initial set of points. Before we apply it to an image, we will start with a simple example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3905915",
      "metadata": {
        "id": "d3905915"
      },
      "outputs": [],
      "source": [
        "arr=np.array([[0,3,4,7,0],[0,4,2,5,0]])\n",
        "theta=np.radians(30)\n",
        "\n",
        "#express rotation matrix that depends on theta, keep its format as numpy array\n",
        "transformation_matrix = np.array([[cos(theta), -sin(theta)],[sin(theta),cos(theta)]])\n",
        "\n",
        "#apply the rotation matrix to arr\n",
        "new_arr= transformation_matrix @ arr\n",
        "\n",
        "plt.plot(arr[0],arr[1],label='original')\n",
        "plt.plot(new_arr[0],new_arr[1],label='transformed')\n",
        "plt.legend()\n",
        "\n",
        "plt.gca().set_aspect('equal', adjustable='box')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Caption\n",
        "Original shape formed by array and its transformed version which is rotated by 30 degrees."
      ],
      "metadata": {
        "id": "xQFa2GU1WWsF"
      },
      "id": "xQFa2GU1WWsF"
    },
    {
      "cell_type": "markdown",
      "id": "06b3cd1b",
      "metadata": {
        "id": "06b3cd1b"
      },
      "source": [
        "Other operations are scaling, and shear, which can be achieved through\n",
        "$$ \\begin{bmatrix}\n",
        "k_1 & 0\\\\\n",
        "0 & k_2\n",
        "\\end{bmatrix} $$\n",
        "for scaling, where $k_1$ is the scaling in $\\hat{x}$, and $k_2$ is the scaling in $\\hat{y}$. And, for shear\n",
        "$$ \\begin{bmatrix}\n",
        "1 & m_1\\\\\n",
        "m_2 & 1\n",
        "\\end{bmatrix} $$\n",
        "where $m_1$ is horizontal shear, and $m_2$ is vertical shear.\n",
        "\n",
        "Repeat the above, applying different transformations, plotting them alongside one another."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "012e9fb1",
      "metadata": {
        "id": "012e9fb1"
      },
      "outputs": [],
      "source": [
        "arr=np.array([[0,3,4,7,0],[0,4,2,5,0]])\n",
        "k1 = 2\n",
        "k2 = 3\n",
        "transformation_matrix = np.array([[k1,0],[0,k2]])\n",
        "scale_arr=transformation_matrix @ arr\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "arr=np.array([[0,3,4,7,0],[0,4,2,5,0]])\n",
        "m1 = 2\n",
        "m2 = 3\n",
        "transformation_matrix = np.array([[1,m1],[m2,1]])\n",
        "sheer_arr=transformation_matrix @ arr\n",
        "\n",
        "\n",
        "plt.plot(arr[0],arr[1],label='original')\n",
        "plt.plot(scale_arr[0],scale_arr[1],label='scaled')\n",
        "plt.plot(sheer_arr[0],sheer_arr[1],label='sheered')\n",
        "plt.legend()\n",
        "plt.gca().set_aspect('equal', adjustable='box')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Caption\n",
        "Original shape formed by array and two different transformations of it. One where it is being scaled and one where it is being sheered."
      ],
      "metadata": {
        "id": "TT7G43BAW_JG"
      },
      "id": "TT7G43BAW_JG"
    },
    {
      "cell_type": "markdown",
      "id": "6184e9cc",
      "metadata": {
        "id": "6184e9cc"
      },
      "source": [
        "Similarly to the simple geometric shapes, we can also transform more complex images.\n",
        "\n",
        "Although this cell has quite a bit of code, the only thing you need to make it working is to express the approriate transformation matrix that performs rotation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f86aacbd",
      "metadata": {
        "id": "f86aacbd"
      },
      "outputs": [],
      "source": [
        "# Define the angle of rotation in degrees\n",
        "angle = 30\n",
        "theta= np.radians(angle)\n",
        "\n",
        "#express rotation matrix that depends on theta, keep its format as numpy array\n",
        "transformation_matrix = np.array([[cos(theta), -sin(theta)],[sin(theta),cos(theta)]])\n",
        "\n",
        "\n",
        "# Calculating the dimensions of the transformed image\n",
        "height, width = image_array.shape[:2]\n",
        "corners = np.array([[0, 0], [width, 0], [width, height], [0, height]])\n",
        "transformed_corners = np.dot(corners, transformation_matrix.T)\n",
        "new_width = int(np.ceil(np.max(transformed_corners[:, 0])) - np.floor(np.min(transformed_corners[:, 0])))\n",
        "new_height = int(np.ceil(np.max(transformed_corners[:, 1])) - np.floor(np.min(transformed_corners[:, 1])))\n",
        "\n",
        "# Create an empty array to store the transformed image\n",
        "transformed_image_array = np.zeros((new_height, new_width, 3), dtype=np.uint8)+255\n",
        "\n",
        "# Calculate the center of the original and transformed images\n",
        "original_center = np.array([width / 2, height / 2])\n",
        "transformed_center = np.array([new_width / 2, new_height / 2])\n",
        "\n",
        "# Perform the transformation\n",
        "for i in range(height):\n",
        "    for j in range(width):\n",
        "        # Calculate the position relative to the original center\n",
        "        position = np.array([j, i]) - original_center\n",
        "        # Apply the transformation using matrix multiplication\n",
        "        transformed_position = np.dot(np.linalg.inv(transformation_matrix), position)\n",
        "        # Calculate the position relative to the transformed center\n",
        "        transformed_position += transformed_center\n",
        "        # Convert the position to integer values\n",
        "        transformed_position = np.round(transformed_position).astype(int)\n",
        "        # Check if the transformed position is within the bounds of the transformed image\n",
        "        if 0 <= transformed_position[1] < new_height and 0 <= transformed_position[0] < new_width:\n",
        "            transformed_image_array[transformed_position[1], transformed_position[0]] = image_array[i,j]\n",
        "\n",
        "# Convert the transformed image array back to PIL image\n",
        "transformed_image = Image.fromarray(transformed_image_array)\n",
        "\n",
        "# Display the original and transformed images\n",
        "display(image)\n",
        "display(transformed_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ad17907",
      "metadata": {
        "id": "1ad17907"
      },
      "source": [
        "#### Question\n",
        "\n",
        "Describe what the code above is doing step by step, in your own words."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Answer\n",
        "We build a rotation matrix as an array which has been given an angle of rotation of 30 degrees. We then use the images shape to find its width and height. From its width and height, we find its corners where we apply the rotation matrix. From these new corners, we can find a new width and height. From the new width and height, we can compare a new center with the old. Then, we iterate through the new width and heights to check each position and apply the rotation matrix then convert the position value to an integer and convert it back to an image."
      ],
      "metadata": {
        "id": "ocJNMgdI3RgN"
      },
      "id": "ocJNMgdI3RgN"
    },
    {
      "cell_type": "markdown",
      "id": "89bf641c",
      "metadata": {
        "id": "89bf641c"
      },
      "source": [
        "----\n",
        "In the image above, every single pixel has been faithfully moved to a new location, but a finite number of pixels moved onto a larger grid, the result is sub-optimal. As such, it would be better to find not the mapping of the original image onto a new grid, but rather to map every single pixel of the new image onto the coordinates of the original image.\n",
        "\n",
        "Copy the above code and modify the for loop to ensure there are no dead pixels in the rotated image. I.e., instead of iterating across every single pixel of the *original* image, we should instead iterate across every pixel of the *transformed* image.\n",
        "\n",
        "\n",
        "Remember that the rotation is defined in counterclockwise direction, and your new \"fixed\" rotated image should have the same orientation as the rotated image above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24fa771f",
      "metadata": {
        "id": "24fa771f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the angle of rotation in degrees\n",
        "angle = 30\n",
        "theta= np.radians(360-angle)\n",
        "\n",
        "#express rotation matrix that depends on theta, keep its format as numpy array\n",
        "transformation_matrix = np.array([[cos(theta), -sin(theta)],[sin(theta),cos(theta)]])\n",
        "\n",
        "\n",
        "# Calculating the dimensions of the transformed image\n",
        "height, width = image_array.shape[:2]\n",
        "corners = np.array([[0, 0], [width, 0], [width, height], [0, height]])\n",
        "transformed_corners = np.dot(corners, transformation_matrix.T)\n",
        "new_width = int(np.ceil(np.max(transformed_corners[:, 0])) - np.floor(np.min(transformed_corners[:, 0])))\n",
        "new_height = int(np.ceil(np.max(transformed_corners[:, 1])) - np.floor(np.min(transformed_corners[:, 1])))\n",
        "\n",
        "# Create an empty array to store the transformed image\n",
        "transformed_image_array = np.zeros((new_height, new_width, 3), dtype=np.uint8)+255\n",
        "\n",
        "# Calculate the center of the original and transformed images\n",
        "original_center = np.array([width / 2, height / 2])\n",
        "transformed_center = np.array([new_width / 2, new_height / 2])\n",
        "\n",
        "# Perform the transformation\n",
        "for i in range(new_height):\n",
        "    for j in range(new_width):\n",
        "        # Calculate the position relative to the original center\n",
        "        position = np.array([j, i]) - transformed_center\n",
        "        # Apply the inverse transformation using matrix multiplication\n",
        "        original_position = np.dot(np.linalg.inv(transformation_matrix), position)\n",
        "        # Calculate the position relative to the transformed center\n",
        "        original_position += original_center\n",
        "        # Convert the position to integer values\n",
        "        original_position = np.round(original_position).astype(int)\n",
        "        # Check if the transformed position is within the bounds of the transformed image\n",
        "        if 0 <= original_position[1] < height and 0 <= original_position[0] < width:\n",
        "            transformed_image_array[i, j] = image_array[original_position[1], original_position[0]]\n",
        "\n",
        "# Convert the transformed image array back to PIL image\n",
        "transformed_image = Image.fromarray(transformed_image_array)\n",
        "\n",
        "# Display the original and transformed images\n",
        "display(image)\n",
        "display(transformed_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d3ce138",
      "metadata": {
        "id": "6d3ce138"
      },
      "source": [
        "Instead of rotation, scale the image up by a factor of 1.5, and apply horizontal sheer of 0.3 (shear should skew image to the right by convention, as you can check doing this in the first part of this excersise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82624755",
      "metadata": {
        "id": "82624755"
      },
      "outputs": [],
      "source": [
        "k = 1.5\n",
        "m = 0.3\n",
        "\n",
        "scale = np.array([[k, 0],[0, k]])\n",
        "sheer = np.array([[1, m],[0, 1]])\n",
        "\n",
        "transformation_matrix = scale @ sheer\n",
        "\n",
        "# Calculating the dimensions of the transformed image\n",
        "height, width = image_array.shape[:2]\n",
        "corners = np.array([[0, 0], [width, 0], [width, height], [0, height]])\n",
        "transformed_corners = np.dot(corners, transformation_matrix.T)\n",
        "new_width = int(np.ceil(np.max(transformed_corners[:, 0])) - np.floor(np.min(transformed_corners[:, 0])))\n",
        "new_height = int(np.ceil(np.max(transformed_corners[:, 1])) - np.floor(np.min(transformed_corners[:, 1])))\n",
        "\n",
        "# Create an empty array to store the transformed image\n",
        "transformed_image_array = np.zeros((new_height, new_width, 3), dtype=np.uint8)+255\n",
        "\n",
        "# Calculate the center of the original and transformed images\n",
        "original_center = np.array([width / 2, height / 2])\n",
        "transformed_center = np.array([new_width / 2, new_height / 2])\n",
        "\n",
        "# Perform the transformation\n",
        "for i in range(new_height):\n",
        "    for j in range(new_width):\n",
        "        # Calculate the position relative to the original center\n",
        "        position = np.array([j, i]) - transformed_center\n",
        "        # Apply the inverse transformation using matrix multiplication\n",
        "        original_position = np.dot(np.linalg.inv(transformation_matrix), position)\n",
        "        # Calculate the position relative to the transformed center\n",
        "        original_position += original_center\n",
        "        # Convert the position to integer values\n",
        "        original_position = np.round(original_position).astype(int)\n",
        "        # Check if the transformed position is within the bounds of the transformed image\n",
        "        if 0 <= original_position[1] < height and 0 <= original_position[0] < width:\n",
        "            transformed_image_array[i, j] = image_array[original_position[1], original_position[0]]\n",
        "\n",
        "# Convert the transformed image array back to PIL image\n",
        "transformed_image = Image.fromarray(transformed_image_array)\n",
        "\n",
        "# Display the original and transformed images\n",
        "display(image)\n",
        "display(transformed_image)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0992e7d1",
      "metadata": {
        "id": "0992e7d1"
      },
      "source": [
        "Now combine all 3 transformations in a singlt transformation matrix: rotation of 90 degrees, scale the image up by a factor of 1.5, and apply horizontal sheer of 0.3. How does the image change depending on the order of operations of rotation and shear?\n",
        "#### Answer\n",
        "Scale can go anywhere without seeming to effect the shape of the image but sheer and rotation effect each other with their order. If you sheer first, the sheer rotates with the image and sheers vertically. If you rotate first, the rotation happens first so you get a vertically sheered image but its rotated in the horizontal."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c14109e",
      "metadata": {
        "id": "3c14109e"
      },
      "source": [
        "# Diagonalization\n",
        "\n",
        "In working with matrices, it is often very useful to diagonalize a matrix. Diagonalization is a powerful technique that allows us to simplify calculations and gain insights into the behavior of a matrix. It involves transforming a square matrix into a diagonal matrix using eigenvectors and eigenvalues.\n",
        "\n",
        "For example, let $$A=\\begin{bmatrix}\n",
        "a_{11} & a_{12}\\\\\n",
        "a_{21} & a_{22}\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "For this matrix $A$ there exists such a matrix $D$ that corresponds to the eigenvalues of $A$ on the diagonal\n",
        "$$D=\\begin{bmatrix}\n",
        "\\lambda_1 & 0\\\\\n",
        "0 & \\lambda_2\n",
        "\\end{bmatrix}$$\n",
        "as well as matrix $P$ consisting of the eigenvectors corresponding to these eigenvalues\n",
        "$$P=\\begin{bmatrix} \\vec{v_1} & \\vec{v_2} \\end{bmatrix}=\\begin{bmatrix}\n",
        "v_{11} & v_{21}\\\\\n",
        "v_{12} & v_{22}\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "Then, if $P$ is invertible, $A=PDP^{-1}$, but also, $D=P^{-1}AP$. We can test it here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e86612ed",
      "metadata": {
        "id": "e86612ed"
      },
      "outputs": [],
      "source": [
        "A=np.matrix([[7,2],[-4,1]])\n",
        "eigenvalues=np.array([5,3])\n",
        "eigenvectors= np.matrix([[1,1],[-1,-2]])\n",
        "\n",
        "D=np.diag(eigenvalues)\n",
        "\n",
        "print(A-np.round(eigenvectors*D*np.linalg.inv(eigenvectors),5))\n",
        "print(D-np.round(np.linalg.inv(eigenvectors)*A*eigenvectors,5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90152597",
      "metadata": {
        "id": "90152597"
      },
      "source": [
        "Rather than doing it by hand, you can use np.linalg.eig to find eigenvalues and eigenvectors of a matrix. Use them to check your work - remember that eigenvectors can be scaled, and thus are not unique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b248d7f",
      "metadata": {
        "id": "1b248d7f"
      },
      "outputs": [],
      "source": [
        "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
        "D=np.diag(eigenvalues)\n",
        "\n",
        "print(A-np.round(eigenvectors*D*np.linalg.inv(eigenvectors),5))\n",
        "print(D-np.round(np.linalg.inv(eigenvectors)*A*eigenvectors,5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7151f889",
      "metadata": {
        "id": "7151f889"
      },
      "source": [
        "Test diagonalization and reconstruction of a matrix using a much larger matrix, e.g., 100x100. You can use np.random.random() to generate values of the matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de1fef10",
      "metadata": {
        "id": "de1fef10"
      },
      "outputs": [],
      "source": [
        "A = np.matrix(np.random.random((100,100)))\n",
        "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
        "D=np.diag(eigenvalues)\n",
        "\n",
        "plt.hist(np.array(A-eigenvectors*D*np.linalg.inv(eigenvectors)).flatten())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e1551d9",
      "metadata": {
        "id": "6e1551d9"
      },
      "source": [
        "Thus, you can store either the original matrix, or a combination of its eigenvalues and eigenvectors (and reconstruct the original afterwards), but since the set of eigenvectors has the same shape as the original matrix, this would not save any space on your hard drive.\n",
        "\n",
        "It is possible, however, create a very simple compression algorithm using a very similar approach. This code can be ran as is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8d2c12c",
      "metadata": {
        "id": "b8d2c12c"
      },
      "outputs": [],
      "source": [
        "# Convert image to grayscale\n",
        "image_gray = np.mean(image, axis=2)\n",
        "\n",
        "# Compute the covariance matrix\n",
        "covariance_matrix = np.cov(image_gray.T)\n",
        "\n",
        "# Compute the eigenvectors and eigenvalues\n",
        "eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
        "\n",
        "# Sort the eigenvectors based on eigenvalues\n",
        "sorted_indices = np.flip(np.argsort(eigenvalues))\n",
        "eigenvalues = eigenvalues[sorted_indices]\n",
        "eigenvectors = eigenvectors[:, sorted_indices]\n",
        "\n",
        "# Set the number of eigenvectors (k) to keep\n",
        "k = 30\n",
        "\n",
        "# Select the top k eigenvectors\n",
        "selected_eigenvectors = eigenvectors[:, :k]\n",
        "\n",
        "# Project the image onto the selected eigenvectors\n",
        "compressed_image = np.dot(image_gray, selected_eigenvectors)\n",
        "\n",
        "# Reconstruct the image using the selected eigenvectors\n",
        "reconstructed_image = np.dot(compressed_image, selected_eigenvectors.T)\n",
        "\n",
        "# Plot original and reconstructed images\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "axs[0].imshow(image_gray, cmap='gray')\n",
        "axs[0].set_title('Original Image')\n",
        "axs[0].axis('off')\n",
        "axs[1].imshow(reconstructed_image, cmap='gray')\n",
        "axs[1].set_title(f'Reconstructed Image (k={k})')\n",
        "axs[1].axis('off')\n",
        "axs[2].imshow(image_gray-reconstructed_image, cmap='gray')\n",
        "axs[2].set_title(f'Difference (k={k})')\n",
        "axs[2].axis('off')\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d04b4d5",
      "metadata": {
        "id": "8d04b4d5"
      },
      "source": [
        "#### Question\n",
        "\n",
        "Describe what the code above is doing step by step, in your own words."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Answer\n",
        "The code first converts tbe image to grayscale then makes a covariance matrix of the grayscale pixel columns and computes the eigenvalues and eigenvectors of it. Then we sort the eigenvectors by eigenvalue and only keep a specified number. We then dot the grayscale image with the kept eigenvectors. Then we dot that image with the kept eigenvectors transposed. Then we plot the original, the reconstructed image, and their difference to visualize the difference with the amount of selected eigenvectors to keep."
      ],
      "metadata": {
        "id": "mVgTsT_g5Rmc"
      },
      "id": "mVgTsT_g5Rmc"
    },
    {
      "cell_type": "markdown",
      "id": "483f67d6",
      "metadata": {
        "id": "483f67d6"
      },
      "source": [
        "----\n",
        "#### Question\n",
        "Why was it important to sort eigenvalues prior to discarding all but 30 of them?\n",
        "Experiment what would happen if you were to set\n",
        "sorted_indices = np.random.permutation(np.arange(len(eigenvalues)))\n",
        "That is to say, rather than selecting 30 largest eigenvalues, you would pick any 30 eigenvalues in a random order."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Answer\n",
        "\n",
        "Sorting the eigenvalues to select the 30 largest ones instead of 30 random ones is important as the most varying parts of the image are going to correspond to the largest eigenvalues. The most varying parts of the image are more important to its reconstruction than random features."
      ],
      "metadata": {
        "id": "PAz0ESQD5cQX"
      },
      "id": "PAz0ESQD5cQX"
    },
    {
      "cell_type": "markdown",
      "id": "8b68eddf",
      "metadata": {
        "id": "8b68eddf"
      },
      "source": [
        "----\n",
        "Use .size or .shape property of numpy arrays to see the number of pixels that are present in the original image. Consider what variables we would need to save in order to produce this image again in compressed form. Assuming the same data format between all the variables, how much smaller would the compressed file be with k=30? What would you consider to be the smallest k to compress the image without significant loses to visual quality, and what would be the compression in this case?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Answer\n",
        "To reproduce the image again in compressed form, we would need to have the k eigenvectors and the image greyscaled. At k=30, the compressed file is 3.6x smaller than the original or 72% reduced. In my opinion, somewhere between k=5 and k=10 makes this specific image no longer comprehendable as the original image."
      ],
      "metadata": {
        "id": "WI8jf41c9kHU"
      },
      "id": "WI8jf41c9kHU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "083a9d48",
      "metadata": {
        "id": "083a9d48"
      },
      "outputs": [],
      "source": [
        "H,W = image_gray.shape\n",
        "original = image_gray.size\n",
        "compressed = k * (H + W)\n",
        "\n",
        "\n",
        "print(\"H, W:\", H, W)\n",
        "print(\"Original:\", original)\n",
        "print(\"Compressed:\", compressed)\n",
        "print(\"Original / Compressed:\", original/compressed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19abb35c",
      "metadata": {
        "id": "19abb35c"
      },
      "source": [
        "## Extra credit\n",
        "\n",
        "In 3d, rotation matrices can be expressed as\n",
        "\n",
        "$$R_x(\\theta)= \\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "0 & \\cos\\theta & -\\sin(\\theta\\\\\n",
        "0 & \\sin\\theta & \\cos(\\theta\n",
        "\\end{bmatrix},\n",
        "R_y(\\theta)= \\begin{bmatrix}\n",
        "\\cos\\theta & 0 & \\sin\\theta\\\\\n",
        "0 & 1 & 0 \\\\\n",
        "-\\sin\\theta &0 & \\cos\\theta\n",
        "\\end{bmatrix},\n",
        "R_z(\\theta)= \\begin{bmatrix}\n",
        "\\cos\\theta & -\\sin\\theta & 0\\\\\n",
        "\\sin\\theta & \\cos\\theta & 0 \\\\\n",
        "0 & 0 & 1\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "You may remember a previous activity where we have created a 3d plot of a sea shell.\n",
        "\n",
        "Modify the code below to rotate the sea shell around x axis by 60 degrees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a2a62fc",
      "metadata": {
        "id": "3a2a62fc"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "u = np.linspace(0, 2*np.pi, 51)\n",
        "v = np.linspace(-2*np.pi, 2*np.pi, 101)\n",
        "uGrid, vGrid = np.meshgrid(u,v)\n",
        "\n",
        "\n",
        "x_orig=5/4.*(1-vGrid/(2*np.pi))*np.cos(2*vGrid)*(1+np.cos(uGrid))+np.cos(2*vGrid)\n",
        "y_orig=5/4.*(1-vGrid/(2*np.pi))*np.sin(2*vGrid)*(1+np.cos(uGrid))+np.sin(2*vGrid)\n",
        "z_orig=10*vGrid/(2*np.pi)+5/4.*(1-vGrid/(2*np.pi))*np.sin(uGrid)+15\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Surface(x=x_orig,\n",
        "                         y=y_orig,\n",
        "                         z=z_orig))\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "generative_ai_disabled": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}